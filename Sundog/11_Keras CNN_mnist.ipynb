{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to shape the data differently then before. Since we're treating the data as 2D images of 28x28 pixels instead of a flattened stream of 784 pixels, we need to shape it accordingly. Depending on the data format Keras is set up for, this may be 1x28x28 or 28x28x1 (the \"1\" indicates a single color channel, as this is just grayscale. If we were dealing with color images, it would be 3 instead of 1 since we'd have red, green, and blue color channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    train_images = mnist_train_images.reshape(mnist_train_images.shape[0], 1, 28, 28)\n",
    "    test_images = mnist_test_images.reshape(mnist_test_images.shape[0], 1, 28, 28)\n",
    "    input_shape = (1, 28, 28)\n",
    "else:\n",
    "    train_images = mnist_train_images.reshape(mnist_train_images.shape[0], 28, 28, 1)\n",
    "    test_images = mnist_test_images.reshape(mnist_test_images.shape[0], 28, 28, 1)\n",
    "    input_shape = (28, 28, 1)\n",
    "    \n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "train_images /= 255\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert our train and test labels to be categorical in one-hot format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = keras.utils.to_categorical(mnist_train_labels, 10)\n",
    "test_labels = keras.utils.to_categorical(mnist_test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check let's print out one of the training images with its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample(num):\n",
    "    # Print the one-hot array of this sample's label \n",
    "    print(train_labels[num])  \n",
    "    \n",
    "    # Print the label converted back to a number\n",
    "    label = train_labels[num].argmax(axis=0)\n",
    "    \n",
    "    # Reshape the 768 values to a 28x28 image\n",
    "    image = train_images[num].reshape([28,28])\n",
    "    \n",
    "    plt.title('Sample: %d  Label: %d' % (num, label))\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEopJREFUeJzt3X2wXHV9x/H3h8hDy4OE5hJDuBBK6QDSEp1tIMViHIQCMxaYJmDGQnCwcVrRCpQhpQ/EqQ5UJdHWDm2QlFgQCE/KWLBQirXYhLIqQiQiDwaScElugECwViR8+8c5l24u+5Tds3v28vu8Zu7c3fM7u+d7zr2fPQ+/c/YoIjCz9OxSdgFmVg6H3yxRDr9Zohx+s0Q5/GaJcvjNEuXwDwhJiyVdV3YdE42kcyXd3+/XvhUkH35J75H0X5JekvSCpO9I+q2y6+qGpG9J+l9Jr+Q/j41rH5L0VUlbJb0o6fo677GfpNFG4ZB0maSQ9P6aYbtLWi7pZUnPSbpwJ2qeMB9+khbk8/6RsmvpxtvKLqBMkvYBvgH8EbAS2A34HeDnZdZVkPMj4ssN2m4DHgQOBv4HOKrOOH8DrKXOCkLSocBcYGRc02LgsPx93wHcJ+nRiPhmJzMwiCRNBv4M+GHZtXQr9TX/rwNExA0RsT0ifhYRd0fEw5D9k0v6d0nPS9oi6XpJ+469WNI6SRdLeljSTyVdI2mqpLskbZP0b/k/C5Jm5GuLhZKelTQi6aJGhUk6Nt8i2SrpB5LmFDHDkk4ChoGLI+KliPhFRHx/3DizyT4Q/qnB23wJuAR4ddzwc4C/jogXI2ItcDVwbgE1L5L0ZL5MH5V0xptH0d/lW28/knRCTcPb87/LiKSNkj4taVIX5VwO/C2wpYv3GAiph//HwHZJKySdMhbUGiL7Yx8AHEEWmsXjxvl94ESyD5IPAHcBlwJTyJbvJ8aN/z6yteNJwKLazeY3JipNB/4F+DSwH/CnwK2ShvL2RZK+0WLeLs8/sL4z7oPjWOAxYEX+ofagpPfWTHsS8PfA+cCbzv2WNA94NSLuHDd8Mtly+kHN4B8A72xRZzueJNsiezvwKeA6SdNq2o8BniJb5pcBt0naL29bAbwG/BrwLrLlXndzXdI3JC1qVISkWUAF+Ieu5mZQRETSP2ShvhbYQPZPcgcwtcG4pwPfr3m+DvhQzfNbgatqnn8c+Fr+eAZZmA6vaf8scE3+eDFwXf74EuCfx037X4EFbc7TMcDewO7AAmAbcGjetiyv4zxgV+CDwFZgSt5+wdg8kK217695372Ax4FDaub//fnj4fx996gZ/0RgXZs1vzH/bYz7EHBaTY3PAqpp/2/gbGAq2S7cL9W0zQfuqzd/LaY5CagCs/Pn3wI+Uvb/bzc/qa/5iYi1EXFuRBxItql7APAFAEn7S7ox31x8GbiObO1Sa1PN45/Veb7XuPHX1zx+Op/eeAcD8/JN/q2StgLvAabVGbfePD0QEdsi4ucRsQL4DnBqTU3rIuKayDb5b8xrOk7SAWRbKn/e4K0/Rfah9JM6ba/kv/epGbYP2QdPVySdI+mhmmVxFDv+HTZGnsjc2HI9mOwDbqTmtf8I7N9BGX8MPBwRqzqbi8GTfPhrRcSPyLYCxg6AXU62NvvNiNgH+AOyXYFuDNc8PohsrTXeerKQ7Vvzs2dEXNHhNIP/r/th6mzO52aRfcA8Kuk54IvArPzI/STgBOAT+fPn8nlZKemSiHiR7ADg0TXvdzRdHhiTdDDZsYPzgV+JiH2BNez4d5guqfb52HJdT7bmn1KzHPeJiE52RU4AzqiZ998GrpT0pQ7eayAkHX5Jh0u6SNKB+fNhss3C1fkoe5Ot0bbm++EXFzDZv5T0y5LeCXwYuKnOONcBH5D0u5ImSdpD0pyxOlvM07756/aQ9DZJHwKOJ9ttALgdmJx3V02SNBeYTrZ1cBfZ7snM/OevgO8DMyNiO1kAjqppfxb4KNkxAoCvAH8habKkw4E/JPswbdcued1jP7sDe5J9WI3m8/dh3tw7sT/Zh9Ku+TGJI4A7I2IEuJsspPtI2iU/iPtedt65+fuOzXuVbEuo0VbSwEs6/GSbpMcAD0j6KVno1wBjR+E/BbwbeInsANxtBUzzP4AngHuBz0fE3eNHiIj1wGlkBw5HydZgF5P/vSRdKumuBu+/K9mBwlGyI9IfB06PiMfy934B+D2yg4gvAYvI9p+35LsJz4395O2/yB8TEc+Pa98OvBgRY5v8l5EdnHs6n8/Pxc51880n2y0Z+3kyIh4FrgRWke1S/QbZB1WtB8gOom4BPgPMjYjn87ZzyLpwHwVeBG6hwe5T3ktzab22iNg6bt5fBV6OiJd2Yv4GinbcVbJekTQD+Amwa0S8Vm41Zl7zmyXL4TdLlDf7zRLlNb9Zovp6Yc+UKVNixowZ/ZykWVLWrVvHli1b2joXpavwSzqZ7ESQScCXW52EMmPGDKrVajeTNLMmKpVK2+N2vNlfcwHIKcCRwHxJR3b6fmbWX93s888CnoiIpyLiVeBGshNTzGwC6Cb809nxIpUN+bAd5NevVyVVR0dHu5icmRWpm/DXO6jwpn7DiFgWEZWIqAwNDXUxOTMrUjfh38COV6gdSP0r1MxsAHUT/geBwyQdImk3si+FuKOYssys1zru6ouI1ySdT3ap6CRgeURM+C81NEtFV/38kX2P250tRzSzgePTe80S5fCbJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miurpFt6R1wDZgO/BaRFSKKMrMeq+r8OfeFxFbCngfM+sjb/abJarb8Adwt6TvSlpYbwRJCyVVJVVHR0e7nJyZFaXb8B8XEe8GTgE+Jun48SNExLKIqEREZWhoqMvJmVlRugp/RDyb/94M3A7MKqIoM+u9jsMvaU9Je489Bk4C1hRVmJn1VjdH+6cCt0sae5+vRsQ3C6lqAK1fv75h26pVq5q+9swzzyy6HANWrlzZtH327NkN24aHh4suZ8LpOPwR8RRwdIG1mFkfuavPLFEOv1miHH6zRDn8Zoly+M0SVcSFPUlo1p23dOnSpq91V19v3HLLLU3bV69e3bBtyZIlRZcz4XjNb5Yoh98sUQ6/WaIcfrNEOfxmiXL4zRLl8Jslyv38bWrWZ9yszcrT6lLr1HnNb5Yoh98sUQ6/WaIcfrNEOfxmiXL4zRLl8Jslyv38bdqwYUPZJdhOanb+RatzAJp97fdbhdf8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1mi3M/fpmZ9xvPmzetjJTZm7ty5TdtvvvnmjtrA/fwASFouabOkNTXD9pN0j6TH89+Te1ummRWtnc3+a4GTxw1bBNwbEYcB9+bPzWwCaRn+iPg28MK4wacBK/LHK4DTC67LzHqs0wN+UyNiBCD/vX+jESUtlFSVVB0dHe1wcmZWtJ4f7Y+IZRFRiYjK0NBQrydnZm3qNPybJE0DyH9vLq4kM+uHTsN/B7Agf7wA+Hox5ZhZv7Ts55d0AzAHmCJpA3AZcAWwUtJ5wDPAhO/obnV99/r16xu2HXvssUWXY20YHh7u+LX+foY2wh8R8xs0nVBwLWbWRz691yxRDr9Zohx+s0Q5/GaJcvjNEuVLenPNuvK6tXLlyqbtrW7x3apbqtnrezlf3eq2i3Tjxo0dv7bVMm+13LrpZhwUXvObJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8ZolyP3+uVb9vM62+BrpVe6q6WebdatWPv3Tp0qbtS5YsKbKcUnjNb5Yoh98sUQ6/WaIcfrNEOfxmiXL4zRLl8Jslyv38OX+Vs9Vq9VXubwVe85slyuE3S5TDb5Yoh98sUQ6/WaIcfrNEOfxmiXI/f87X3L/1zJvX+Z3jW/0/tDoPYPbs2R1Pu19arvklLZe0WdKammGLJW2U9FD+c2pvyzSzorWz2X8tcHKd4UsjYmb+c2exZZlZr7UMf0R8G3ihD7WYWR91c8DvfEkP57sFkxuNJGmhpKqk6ujoaBeTM7MidRr+q4BDgZnACHBloxEjYllEVCKiMjQ01OHkzKxoHYU/IjZFxPaIeB24GphVbFlm1msdhV/StJqnZwBrGo1rZoOpZT+/pBuAOcAUSRuAy4A5kmYCAawDPtrDGie8Vvdyb3Wf+rlz5zZtb9anPJHvI9+qL73Vd+83Wy6t3rvbezFMhH7+luGPiPl1Bl/Tg1rMrI98eq9Zohx+s0Q5/GaJcvjNEuXwmyXKl/Tmbrrppqbtzb7au9WloxO5u61MrbrLuulO6/arud8KX/XuNb9Zohx+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvlihFRN8mVqlUolqt9m16Zp1qdQ7Bxo0bm7Y/88wzRZbTtkqlQrVaVTvjes1vliiH3yxRDr9Zohx+s0Q5/GaJcvjNEuXwmyXK1/Ob1XHBBRc0bT/rrLOati9ZsqRp+4UXXrjTNRXNa36zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEtr+eXNAx8BXgH8DqwLCK+KGk/4CZgBtltus+MiBebvZev57eJotXtvw866KCu3r9X36NR9PX8rwEXRcQRwLHAxyQdCSwC7o2Iw4B78+dmNkG0DH9EjETE9/LH24C1wHTgNGBFPtoK4PReFWlmxdupfX5JM4B3AQ8AUyNiBLIPCGD/ooszs95pO/yS9gJuBT4ZES/vxOsWSqpKqo6OjnZSo5n1QFvhl7QrWfCvj4jb8sGbJE3L26cBm+u9NiKWRUQlIipDQ0NF1GxmBWgZfkkCrgHWRkTtpUp3AAvyxwuArxdfnpn1SjuX9B4HnA08IumhfNilwBXASknnAc8Aze9TbTaBpHBb9Zbhj4j7gUb9hicUW46Z9YvP8DNLlMNvliiH3yxRDr9Zohx+s0Q5/GaJ8ld3m3Vg3rzmp7WsXr26T5V0zmt+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliiH3yxR7uc368CVV17ZtH3VqlV9qqRzXvObJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8ZolyP79ZB1p9r/9E+N5/r/nNEuXwmyXK4TdLlMNvliiH3yxRDr9Zohx+s0S1DL+kYUn3SVor6YeS/iQfvljSRkkP5T+n9r5cMytKOyf5vAZcFBHfk7Q38F1J9+RtSyPi870rz8x6pWX4I2IEGMkfb5O0Fpje68LMrLd2ap9f0gzgXcAD+aDzJT0sabmkyQ1es1BSVVJ1dHS0q2LNrDhth1/SXsCtwCcj4mXgKuBQYCbZlkHdLzWLiGURUYmIytDQUAElm1kR2gq/pF3Jgn99RNwGEBGbImJ7RLwOXA3M6l2ZZla0do72C7gGWBsRS2qGT6sZ7QxgTfHlmVmvtHO0/zjgbOARSQ/lwy4F5kuaCQSwDvhoTyo0s55o52j//YDqNN1ZfDlm1i8+w88sUQ6/WaIcfrNEOfxmiXL4zRLl8JslyuE3S5TDb5Yoh98sUQ6/WaIcfrNEOfxmiXL4zRLl8JslShHRv4lJo8DTNYOmAFv6VsDOGdTaBrUucG2dKrK2gyOire/L62v43zRxqRoRldIKaGJQaxvUusC1daqs2rzZb5Yoh98sUWWHf1nJ029mUGsb1LrAtXWqlNpK3ec3s/KUveY3s5I4/GaJKiX8kk6W9JikJyQtKqOGRiStk/RIftvxasm1LJe0WdKammH7SbpH0uP577r3SCyptoG4bXuT28qXuuwG7Xb3fd/nlzQJ+DFwIrABeBCYHxGP9rWQBiStAyoRUfoJIZKOB14BvhIRR+XDPgu8EBFX5B+ckyPikgGpbTHwStm3bc/vJjWt9rbywOnAuZS47JrUdSYlLLcy1vyzgCci4qmIeBW4ETithDoGXkR8G3hh3ODTgBX54xVk/zx916C2gRARIxHxvfzxNmDstvKlLrsmdZWijPBPB9bXPN9AiQugjgDulvRdSQvLLqaOqRExAtk/E7B/yfWM1/K27f007rbyA7PsOrndfdHKCH+9W38NUn/jcRHxbuAU4GP55q21p63btvdLndvKD4ROb3dftDLCvwEYrnl+IPBsCXXUFRHP5r83A7czeLce3zR2h+T89+aS63nDIN22vd5t5RmAZTdIt7svI/wPAodJOkTSbsAHgTtKqONNJO2ZH4hB0p7ASQzercfvABbkjxcAXy+xlh0Mym3bG91WnpKX3aDd7r6UM/zyrowvAJOA5RHxmb4XUYekXyVb20N2B+OvllmbpBuAOWSXfG4CLgO+BqwEDgKeAeZFRN8PvDWobQ7Zpusbt20f28fuc23vAf4TeAR4PR98Kdn+dWnLrkld8ylhufn0XrNE+Qw/s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliiH3yxR/wcCduDHhoAa6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aaf040fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sample(np.random.randint(60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))  # 64 3x3 kernels\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))         # Reduce by taking the max of each 2x2 block\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten the results to one dimension for passing into our final layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Final categorization from 0-9 with softmax\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 264s 4ms/step - loss: 0.4524 - acc: 0.8652\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 274s 5ms/step - loss: 0.1251 - acc: 0.9636\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 268s 4ms/step - loss: 0.0857 - acc: 0.9752\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 264s 4ms/step - loss: 0.0687 - acc: 0.9793\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 261s 4ms/step - loss: 0.0595 - acc: 0.9817\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 265s 4ms/step - loss: 0.0486 - acc: 0.9855\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 262s 4ms/step - loss: 0.0445 - acc: 0.9856\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 262s 4ms/step - loss: 0.0410 - acc: 0.9875\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 262s 4ms/step - loss: 0.0372 - acc: 0.9883\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 262s 4ms/step - loss: 0.0353 - acc: 0.9890\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=600,\n",
    "                    epochs=10,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.028963799416649273\n",
      "Test accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
